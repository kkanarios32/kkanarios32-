<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1870</fr:anchor><fr:addr
type="user">deepseekai2025deepseekr1incentivizingreasoningcapability</fr:addr><fr:route>deepseekai2025deepseekr1incentivizingreasoningcapability.xml</fr:route><fr:title
text="DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning">DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning</fr:title><fr:taxon>Reference</fr:taxon><fr:date><fr:year>2025</fr:year></fr:date><fr:authors><fr:author></fr:author><fr:author>Daya Guo</fr:author><fr:author>Dejian Yang</fr:author><fr:author>Haowei Zhang</fr:author><fr:author>Junxiao Song</fr:author><fr:author>Ruoyu Zhang</fr:author><fr:author>Runxin Xu</fr:author><fr:author>Qihao Zhu</fr:author><fr:author>Shirong Ma</fr:author><fr:author>Peiyi Wang</fr:author><fr:author>Xiao Bi</fr:author><fr:author>Xiaokang Zhang</fr:author><fr:author>Xingkai Yu</fr:author><fr:author>Yu Wu</fr:author><fr:author>Z. F. Wu</fr:author><fr:author>Zhibin Gou</fr:author><fr:author>Zhihong Shao</fr:author><fr:author>Zhuoshu Li</fr:author><fr:author>Ziyi Gao</fr:author><fr:author>Aixin Liu</fr:author><fr:author>Bing Xue</fr:author><fr:author>Bingxuan Wang</fr:author><fr:author>Bochao Wu</fr:author><fr:author>Bei Feng</fr:author><fr:author>Chengda Lu</fr:author><fr:author>Chenggang Zhao</fr:author><fr:author>Chengqi Deng</fr:author><fr:author>Chenyu Zhang</fr:author><fr:author>Chong Ruan</fr:author><fr:author>Damai Dai</fr:author><fr:author>Deli Chen</fr:author><fr:author>Dongjie Ji</fr:author><fr:author>Erhang Li</fr:author><fr:author>Fangyun Lin</fr:author><fr:author>Fucong Dai</fr:author><fr:author>Fuli Luo</fr:author><fr:author>Guangbo Hao</fr:author><fr:author>Guanting Chen</fr:author><fr:author>Guowei Li</fr:author><fr:author>H. Zhang</fr:author><fr:author>Han Bao</fr:author><fr:author>Hanwei Xu</fr:author><fr:author>Haocheng Wang</fr:author><fr:author>Honghui Ding</fr:author><fr:author>Huajian Xin</fr:author><fr:author>Huazuo Gao</fr:author><fr:author>Hui Qu</fr:author><fr:author>Hui Li</fr:author><fr:author>Jianzhong Guo</fr:author><fr:author>Jiashi Li</fr:author><fr:author>Jiawei Wang</fr:author><fr:author>Jingchang Chen</fr:author><fr:author>Jingyang Yuan</fr:author><fr:author>Junjie Qiu</fr:author><fr:author>Junlong Li</fr:author><fr:author>J. L. Cai</fr:author><fr:author>Jiaqi Ni</fr:author><fr:author>Jian Liang</fr:author><fr:author>Jin Chen</fr:author><fr:author>Kai Dong</fr:author><fr:author>Kai Hu</fr:author><fr:author>Kaige Gao</fr:author><fr:author>Kang Guan</fr:author><fr:author>Kexin Huang</fr:author><fr:author>Kuai Yu</fr:author><fr:author>Lean Wang</fr:author><fr:author>Lecong Zhang</fr:author><fr:author>Liang Zhao</fr:author><fr:author>Litong Wang</fr:author><fr:author>Liyue Zhang</fr:author><fr:author>Lei Xu</fr:author><fr:author>Leyi Xia</fr:author><fr:author>Mingchuan Zhang</fr:author><fr:author>Minghua Zhang</fr:author><fr:author>Minghui Tang</fr:author><fr:author>Meng Li</fr:author><fr:author>Miaojun Wang</fr:author><fr:author>Mingming Li</fr:author><fr:author>Ning Tian</fr:author><fr:author>Panpan Huang</fr:author><fr:author>Peng Zhang</fr:author><fr:author>Qiancheng Wang</fr:author><fr:author>Qinyu Chen</fr:author><fr:author>Qiushi Du</fr:author><fr:author>Ruiqi Ge</fr:author><fr:author>Ruisong Zhang</fr:author><fr:author>Ruizhe Pan</fr:author><fr:author>Runji Wang</fr:author><fr:author>R. J. Chen</fr:author><fr:author>R. L. Jin</fr:author><fr:author>Ruyi Chen</fr:author><fr:author>Shanghao Lu</fr:author><fr:author>Shangyan Zhou</fr:author><fr:author>Shanhuang Chen</fr:author><fr:author>Shengfeng Ye</fr:author><fr:author>Shiyu Wang</fr:author><fr:author>Shuiping Yu</fr:author><fr:author>Shunfeng Zhou</fr:author><fr:author>Shuting Pan</fr:author><fr:author>S. S. Li</fr:author><fr:author>Shuang Zhou</fr:author><fr:author>Shaoqing Wu</fr:author><fr:author>Shengfeng Ye</fr:author><fr:author>Tao Yun</fr:author><fr:author>Tian Pei</fr:author><fr:author>Tianyu Sun</fr:author><fr:author>T. Wang</fr:author><fr:author>Wangding Zeng</fr:author><fr:author>Wanjia Zhao</fr:author><fr:author>Wen Liu</fr:author><fr:author>Wenfeng Liang</fr:author><fr:author>Wenjun Gao</fr:author><fr:author>Wenqin Yu</fr:author><fr:author>Wentao Zhang</fr:author><fr:author>W. L. Xiao</fr:author><fr:author>Wei An</fr:author><fr:author>Xiaodong Liu</fr:author><fr:author>Xiaohan Wang</fr:author><fr:author>Xiaokang Chen</fr:author><fr:author>Xiaotao Nie</fr:author><fr:author>Xin Cheng</fr:author><fr:author>Xin Liu</fr:author><fr:author>Xin Xie</fr:author><fr:author>Xingchao Liu</fr:author><fr:author>Xinyu Yang</fr:author><fr:author>Xinyuan Li</fr:author><fr:author>Xuecheng Su</fr:author><fr:author>Xuheng Lin</fr:author><fr:author>X. Q. Li</fr:author><fr:author>Xiangyue Jin</fr:author><fr:author>Xiaojin Shen</fr:author><fr:author>Xiaosha Chen</fr:author><fr:author>Xiaowen Sun</fr:author><fr:author>Xiaoxiang Wang</fr:author><fr:author>Xinnan Song</fr:author><fr:author>Xinyi Zhou</fr:author><fr:author>Xianzu Wang</fr:author><fr:author>Xinxia Shan</fr:author><fr:author>Y. K. Li</fr:author><fr:author>Y. Q. Wang</fr:author><fr:author>Y. X. Wei</fr:author><fr:author>Yang Zhang</fr:author><fr:author>Yanhong Xu</fr:author><fr:author>Yao Li</fr:author><fr:author>Yao Zhao</fr:author><fr:author>Yaofeng Sun</fr:author><fr:author>Yaohui Wang</fr:author><fr:author>Yi Yu</fr:author><fr:author>Yichao Zhang</fr:author><fr:author>Yifan Shi</fr:author><fr:author>Yiliang Xiong</fr:author><fr:author>Ying He</fr:author><fr:author>Yishi Piao</fr:author><fr:author>Yisong Wang</fr:author><fr:author>Yixuan Tan</fr:author><fr:author>Yiyang Ma</fr:author><fr:author>Yiyuan Liu</fr:author><fr:author>Yongqiang Guo</fr:author><fr:author>Yuan Ou</fr:author><fr:author>Yuduan Wang</fr:author><fr:author>Yue Gong</fr:author><fr:author>Yuheng Zou</fr:author><fr:author>Yujia He</fr:author><fr:author>Yunfan Xiong</fr:author><fr:author>Yuxiang Luo</fr:author><fr:author>Yuxiang You</fr:author><fr:author>Yuxuan Liu</fr:author><fr:author>Yuyang Zhou</fr:author><fr:author>Y. X. Zhu</fr:author><fr:author>Yanhong Xu</fr:author><fr:author>Yanping Huang</fr:author><fr:author>Yaohui Li</fr:author><fr:author>Yi Zheng</fr:author><fr:author>Yuchen Zhu</fr:author><fr:author>Yunxian Ma</fr:author><fr:author>Ying Tang</fr:author><fr:author>Yukun Zha</fr:author><fr:author>Yuting Yan</fr:author><fr:author>Z. Z. Ren</fr:author><fr:author>Zehui Ren</fr:author><fr:author>Zhangli Sha</fr:author><fr:author>Zhe Fu</fr:author><fr:author>Zhean Xu</fr:author><fr:author>Zhenda Xie</fr:author><fr:author>Zhengyan Zhang</fr:author><fr:author>Zhewen Hao</fr:author><fr:author>Zhicheng Ma</fr:author><fr:author>Zhigang Yan</fr:author><fr:author>Zhiyu Wu</fr:author><fr:author>Zihui Gu</fr:author><fr:author>Zijia Zhu</fr:author><fr:author>Zijun Liu</fr:author><fr:author>Zilin Li</fr:author><fr:author>Ziwei Xie</fr:author><fr:author>Ziyang Song</fr:author><fr:author>Zizheng Pan</fr:author><fr:author>Zhen Huang</fr:author><fr:author>Zhipeng Xu</fr:author><fr:author>Zhongyu Zhang</fr:author><fr:author>Zhen Zhang</fr:author></fr:authors><fr:meta
name="external">https://arxiv.org/abs/2501.12948</fr:meta><fr:meta
name="bibtex"><![CDATA[@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
 title = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via
Reinforcement Learning},
 author = {DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and
Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong
Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and
Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and
Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu
and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and
Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie
Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and
Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao
and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and
Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and
Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and
Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and
Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and
Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang
and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and
Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and
Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and
Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong
Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and
Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and
Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and
Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and
Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and
Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and
Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An
and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie
and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang
and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and
Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and
Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and
Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang
and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui
Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and
Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma
and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue
Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and
Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong
Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and
Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren
and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie
and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and
Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and
Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng
Xu and Zhongyu Zhang and Zhen Zhang},
 year = {2025},
 url = {https://arxiv.org/abs/2501.12948},
 primaryclass = {cs.CL},
 archiveprefix = {arXiv},
 eprint = {2501.12948}
}]]></fr:meta></fr:frontmatter><fr:mainmatter /><fr:backmatter><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="Backlinks">Backlinks</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2071</fr:anchor><fr:addr
type="user">kak-003D</fr:addr><fr:route>kak-003D.xml</fr:route><fr:title
text="Deepseek v1 through R1: RL is back!">Deepseek v1 through R1: RL is back!</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>In this blog, we will aim to understand the key contributions of <fr:link
type="local"
href="deepseekai2025deepseekr1incentivizingreasoningcapability.xml"
addr="deepseekai2025deepseekr1incentivizingreasoningcapability"
title="DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning">DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning</fr:link>. It will serve as the complement to my group meeting presentation possibly consisting of more in-depth explanations. Time permitting, we might go over the engineering innovations introduced in <fr:link
type="local"
href="deepseekai2024deepseekv3technicalreport.xml"
addr="deepseekai2024deepseekv3technicalreport"
title="DeepSeek-V3 technical report">DeepSeek-V3 technical report</fr:link>.</fr:p>
  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>452</fr:anchor><fr:addr
type="machine">#292</fr:addr><fr:route>unstable-292.xml</fr:route><fr:title
text="Background">Background</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    By request of my advisor, I will cover the basics of LLMs prior to the innovations in the Deepseek lineage. For those familiar with LLMs, please skip this section.
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>454</fr:anchor><fr:addr
type="user">kak-004J</fr:addr><fr:route>kak-004J.xml</fr:route><fr:title
text="Word Embeddings">Word Embeddings</fr:title><fr:date><fr:year>2025</fr:year><fr:month>2</fr:month><fr:day>3</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tex
display="block"><![CDATA[\mathrm {Tok}(\mathbf {x})=\begin {bmatrix} 132\\ 17 \\ 87\\ 83\\ 184\end {bmatrix}]]></fr:tex></fr:mainmatter><fr:backmatter /></fr:tree>
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>455</fr:anchor><fr:addr
type="user">kak-004G</fr:addr><fr:route>kak-004G.xml</fr:route><fr:title
text="Self-Attention">Self-Attention</fr:title><fr:date><fr:year>2025</fr:year><fr:month>2</fr:month><fr:day>1</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>TLDR: Learned weighting of token embeddings. Essentially, learning which words to "attend" to in the input sequence. Have matrices
<fr:tex
display="inline"><![CDATA[\mathbf {Q} = \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {q}^{(1)} & \text {---}   \end {bmatrix} \\   \vdots  \\   \begin {bmatrix}     \text {---} & \mathbf {q}^{(n)} & \text {---}   \end {bmatrix} \end {bmatrix} \in  \mathbb {R}^{n \times  d_q}]]></fr:tex>, 
<fr:tex
display="inline"><![CDATA[ \mathbf {K} = \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {k}^{(1)} & \text {---}   \end {bmatrix} \\   \vdots  \\   \begin {bmatrix}     \text {---} & \mathbf {k}^{(n)} & \text {---}   \end {bmatrix} \end {bmatrix} \in  \mathbb {R}^{n \times  d_k} ]]></fr:tex>
<fr:tex
display="inline"><![CDATA[ \mathbf {V} = \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {v}^{(1)} & \text {---}   \end {bmatrix} \\   \vdots  \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(n)} & \text {---}   \end {bmatrix} \end {bmatrix} \in  \mathbb {R}^{n \times  d_v} ]]></fr:tex></fr:p><fr:p><fr:strong>Intuition 1:</fr:strong> Convex re-weighting of input tokens.
  Note that
<fr:tex
display="block"><![CDATA[ \begin {align*}   \begin {bmatrix}     p_1 & p_2 & p_3   \end {bmatrix} \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {v}^{(1)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(2)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(3)} & \text {---}   \end {bmatrix}   \end {bmatrix} = p_1 \mathbf {v}^{(1)} + p_2 \mathbf {v}^{(2)} + p_3 \mathbf {v}^{(3)} \end {align*}   ]]></fr:tex>
<fr:tex
display="block"><![CDATA[ \begin {align*}   \begin {bmatrix}     p_{11} & 0 & 0 \\     p_{21} & p_{22} & 0 \\     p_{31} & p_{32} & p_{33}   \end {bmatrix} \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {v}^{(1)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(2)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(3)} & \text {---}   \end {bmatrix}   \end {bmatrix} =    \begin {bmatrix}   p_{11} \mathbf {v}^{(1)}  \\   p_{21} \mathbf {v}^{(1)} + p_{22} \mathbf {v}^{(2)} \\   p_{31} \mathbf {v}^{(1)} + p_{32} \mathbf {v}^{(2)} + p_{33} \mathbf {v}^{(3)}   \end {bmatrix} \end {align*}   ]]></fr:tex>
  <fr:strong>Intuition 2:</fr:strong> Context dependent re-weighting.
      If <fr:tex
display="inline"><![CDATA[\mathbf {p} = \mathbb {S}(\mathbf {Q} \mathbf {K}^T)]]></fr:tex> then
      <fr:tex
display="block"><![CDATA[         \begin {align*}           p_{ij} = \frac {\mathbf {q}^{(i)} \cdot  \mathbf {k}^{(j)}}{\sum _{j} \mathbf {q}^{(i)} \cdot  \mathbf {k}^{(j)}}         \end {align*}       ]]></fr:tex></fr:p>
   
   <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>457</fr:anchor><fr:addr
type="machine">#264</fr:addr><fr:route>unstable-264.xml</fr:route><fr:taxon>Example</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>2</fr:month><fr:day>1</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    Suppose that <fr:tex
display="inline"><![CDATA[\mathbf {x} = \text {I play with the ball}]]></fr:tex>. Then 
<fr:tex
display="block"><![CDATA[     \begin {align*}       \mathbf {x}^{(5)} = \mathrm {Embed}(\text {``ball"})     \end {align*}   ]]></fr:tex>
  A feasible query for "ball" would be a verb describing the action of the ball, so maybe
  <fr:tex
display="block"><![CDATA[   \begin {align*}       W_q \mathbf {x}^{(5)} = \mathrm {Embed}(\text {``play"})   \end {align*}   ]]></fr:tex>
  and a key for "play" would be what you are playing with like a ball, so 
  <fr:tex
display="block"><![CDATA[   \begin {align*}       W_k \mathbf {x}^{(2)} = \mathrm {Embed}(\text {``ball"})   \end {align*}   ]]></fr:tex>
  i.e.
<fr:tex
display="block"><![CDATA[   \begin {align*}     \mathrm {Query}(\text {``quantum"}) \cdot  \mathrm {Key}(\text {``mechanics"}) \approx      ||\mathrm {Query}(\text {``quantum"})|| \cdot  ||\mathrm {Key}(\text {``mechanics"})||   \end {align*} ]]></fr:tex>

</fr:mainmatter><fr:backmatter /></fr:tree>
 
<fr:p><fr:tex
display="block"><![CDATA[   \begin {align*} \left [\mathbb {S}(\mathbf {Q}\mathbf {K}^T)\right ]_{4} &= \mathbb {S}\left (\begin {bmatrix} \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(1)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(2)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(3)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(4)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(5)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(6)} \end {bmatrix} \right ) \\ &= \begin {bmatrix} 0 & 0.2 & 0.3 & 0.5 & 0 & 0 \end {bmatrix}   \end {align*} ]]></fr:tex>
<fr:tex
display="block"><![CDATA[ \left [\mathbb {S}(\mathbf {Q}\mathbf {K}^T)\right ]_{4} \mathbf {V} = 0.2 \mathbf {v}^{(2)} + 0.3 \mathbf {v}^{(3)} + 0.5 \mathbf {v}^{(5)} ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree>
    
  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>459</fr:anchor><fr:addr
type="machine">#291</fr:addr><fr:route>unstable-291.xml</fr:route><fr:title
text="RLHF">RLHF</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
<fr:tex
display="block"><![CDATA[\mathrm {loss}\left (\phi \right )=E_{\left (x,y\right )\sim  D_{\pi _{\phi }^{\mathrm {RL}}}}\left [r_\theta (x,y)-\beta \log \left (\pi _{\phi }^{\mathrm {RL}}(y\mid  x)/\pi ^{\mathrm {SFT}}(y\mid  x)\right )\right ] + \gamma  E_{x\sim  D_{\mathrm {pretrain}}}\left [\log (\pi _{\phi }^{\mathrm {RL}}(x))\right ]]]></fr:tex>
      </fr:mainmatter><fr:backmatter /></fr:tree>
  

</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>461</fr:anchor><fr:addr
type="machine">#293</fr:addr><fr:route>unstable-293.xml</fr:route><fr:title
text="Deepseek v2">Deepseek v2</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    Paper 
  </fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>463</fr:anchor><fr:addr
type="machine">#294</fr:addr><fr:route>unstable-294.xml</fr:route><fr:title
text="Deepseek v3">Deepseek v3</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
TODO. Kinda wanna look into the architectural / training innovations from this paper.
  </fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>465</fr:anchor><fr:addr
type="machine">#298</fr:addr><fr:route>unstable-298.xml</fr:route><fr:title
text="Deepseek R1">Deepseek R1</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>


  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>467</fr:anchor><fr:addr
type="machine">#295</fr:addr><fr:route>unstable-295.xml</fr:route><fr:title
text="How is R1 different then previous iterations of models?">How is R1 different then previous iterations of models?</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>In R1-Zero, they do <fr:strong>ZERO</fr:strong> SFT on the base model - directly apply reinforcement learning.</fr:li>
    <fr:li>Use PPO like policy optimization but do <fr:strong>NOT</fr:strong> learn a reward model.</fr:li>
    <fr:ul><fr:li>Use very simple reward: 
        <fr:ul><fr:li><fr:tex
display="inline"><![CDATA[+1]]></fr:tex> for correct answer</fr:li> 
          <fr:li><fr:tex
display="inline"><![CDATA[-0.5]]></fr:tex> for incorrect answer</fr:li> 
          <fr:li><fr:tex
display="inline"><![CDATA[-1]]></fr:tex> for inability to answer.</fr:li></fr:ul></fr:li></fr:ul></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  


<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>469</fr:anchor><fr:addr
type="user">kak-003X</fr:addr><fr:route>kak-003X.xml</fr:route><fr:title
text="Group Relative Policy Optimization">Group Relative Policy Optimization</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Traditional actor critic RL algorithms, require training both an actor and a critic (as the name implies). Typically, these components are both of equal size. In the field of RL, this is non-problematic because models are typically rather small (at least in comparison to LLMs).
In <fr:link
type="local"
href="shao2024deepseekmathpushinglimitsmathematical.xml"
addr="shao2024deepseekmathpushinglimitsmathematical"
title="DeepSeekMath: Pushing the limits of mathematical reasoning in open language models">DeepSeekMath: Pushing the limits of mathematical reasoning in open language models</fr:link></fr:p>
  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>470</fr:anchor><fr:addr
type="machine">#288</fr:addr><fr:route>unstable-288.xml</fr:route><fr:title
text="Math">Math</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter>
  <fr:tex
display="block"><![CDATA[     \begin {align*}     {\mathcal {J}}_{\mathrm {GRPO}}(\theta )&= \mathbb {E}[q\sim  P(Q),\{o_{i}\}_{i=1}^{G}\sim \pi _{\theta _{o l d}}(O|q)] \\     &= \frac {1}{G}\sum _{i=1}^{G}\left (\operatorname *{min}\left (\frac {\pi _{\theta }(o_{i}|q)}{\pi _{\theta _{o d}}(o_{i}|q)}A_{i},\operatorname *{clip}\left (\frac {\pi _{\theta }(o_{i}|q)}{\pi _{\theta _{o d d}}(o_{i}|q)},1-\varepsilon ,1+\varepsilon \right )A_{i}\right )-\beta \mathbb {D}_{K L}\left (\pi _{\theta }||\pi _{r e f}\right )\right )     \end {align*}   ]]></fr:tex>
  where
  <fr:tex
display="block"><![CDATA[         \mathbb {D}_{\mathrm {K L}}\left (\pi _{\theta }||\pi _{\mathrm {ref}}\right )=\frac {\pi _{\mathrm {ref}}(o_{i}|q)}{\pi _{\theta }(o_{i}|q)}-\log \frac {\pi _{\mathrm {ref}}(o_{i}|q)}{\pi _{\theta }(o_{i}|q)}-1     ]]></fr:tex>
    The astute RL reader will notice this is essentially <fr:link
type="local"
href="schulman2017proximalpolicyoptimizationalgorithms.xml"
addr="schulman2017proximalpolicyoptimizationalgorithms"
title="Proximal policy optimization algorithms">PPO</fr:link>.
    The key distinction here is that the advantage <fr:tex
display="inline"><![CDATA[A_i]]></fr:tex> is not computed using a critic model. Instead, 
<fr:tex
display="block"><![CDATA[A_{i}=\frac {r_{i}-\mathrm {mean}(\{r_{1},r_{2},\cdots ,r_{G}\})}{\mathrm {std}(\{r_{1},r_{2},\cdots ,r_{G}\})}.]]></fr:tex>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter /></fr:tree>


  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>471</fr:anchor><fr:addr
type="machine">#296</fr:addr><fr:route>unstable-296.xml</fr:route><fr:title
text="Post-training">Post-training</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    <fr:ul><fr:li><fr:em>Reinforcement Learning for all Scenarios:</fr:em> Seems like they do RLHF after the pure RL stage.</fr:li>
        <fr:ul><fr:li>Do traditional helpfulness harmfulness RLHF with trained reward model.</fr:li></fr:ul></fr:ul>
  </fr:mainmatter><fr:backmatter /></fr:tree>
  



  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>473</fr:anchor><fr:addr
type="machine">#297</fr:addr><fr:route>unstable-297.xml</fr:route><fr:title
text="Distilling Models with R1">Distilling Models with R1</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>To distill, they do only SFT with R1 generated COT.</fr:li>
      <fr:li>They show that distillation outperforms doing pure RL approach on smaller model</fr:li>
      <fr:ul><fr:li>Seems contradictory to <fr:link
type="local"
href="zeng2025simplerl.xml"
addr="zeng2025simplerl"
title="7B model and 8K examples: Emerging reasoning with reinforcement learning is both effective and efficient">7B model and 8K examples: Emerging reasoning with reinforcement learning is both effective and efficient</fr:link></fr:li></fr:ul></fr:ul>
  </fr:mainmatter><fr:backmatter /></fr:tree>
  


</fr:mainmatter><fr:backmatter /></fr:tree>
  

  <html:hr
xmlns:html="http://www.w3.org/1999/xhtml" />
<html:script
xmlns:html="http://www.w3.org/1999/xhtml"
src="https://utteranc.es/client.js"
repo="kkanarios32/website-comments"
issue-term="pathname"
theme="boxy-light"
crossorigin="anonymous"
async="" /></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:backmatter></fr:tree>