<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>3476</fr:anchor><fr:addr
type="user">log-0005</fr:addr><fr:route>log-0005.xml</fr:route><fr:title
text="11/18/2024">11/18/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>Today we kind of got back on track.</fr:p>
  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2585</fr:anchor><fr:addr
type="machine">#248</fr:addr><fr:route>unstable-248.xml</fr:route><fr:title
text="Daily Summary">Daily Summary</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    <fr:strong>Contrastive RL:</fr:strong> As a way to avoid struggling with mujoco, I re-immersed myself in the relevant literature. I had a few takeaways:
    <fr:ul><fr:li>I took a look back at the <fr:link
type="local"
href="mcleod2022.xml"
addr="mcleod2022"
title="Continual Auxiliary Task Learning">Continual Auxiliary Task Learning</fr:link> paper. I still really want to implement a system that puts everything together. Namely,</fr:li>
      <fr:ul><fr:li>In this paper, they do not learn the cumulants that they use to compute the successor features.</fr:li>
          <fr:li>Also, is a continual optimizer enough for non-stationary MDPs when learning cumulants?</fr:li></fr:ul>
        <fr:li>Regarding implementation details for the Contrastive RL stuff. It seems the first priority should actually be implementing the hierarchical policy.</fr:li>
        <fr:ul><fr:li>Currently, the repo is set up to randomly select goals and see how well the goal-conditioned policy can reach them. This is basically the extent of experimentation needed without the hierarchical policy.</fr:li></fr:ul>
      <fr:li>I did come across an alternative successor-feature like apprach that I want to take a closer look at: the Forward-Backward representation <fr:link
type="external"
href="https://openreview.net/pdf?id=MYEap_OcQI">Toutati et al. 2023</fr:link>, <fr:link
type="external"
href="http://www.yann-ollivier.org/rech/publs/allpolicies.pdf">Toutati et al. 2021</fr:link>, <fr:link
type="external"
href="https://arxiv.org/pdf/2101.07123">Blier et al. 2021</fr:link>. Initial impressions:</fr:li>
      <fr:ul><fr:li>Seems to be learned in a very similar manner to the successor feature stuff.</fr:li>
          <fr:li>Re-parametrization avoids converging to trivial 0 solution.</fr:li>
          <fr:li>Experimentally, seems way better than contrastive (at least for zero shot RL).</fr:li></fr:ul></fr:ul>
<fr:strong>Weak-to-strong Generalization:</fr:strong> I finished up my slides for our presentation tomorrow.
<fr:ul><fr:li>I have sufficiently confused myself on what weak-to-strong generalization even means. Is it</fr:li>
    <fr:ol><fr:li>Correctly answering things that the weak model got incorrect? or</fr:li>
        <fr:li>Generalizing correct answers on easier tasks to harder tasks?</fr:li></fr:ol>
      <fr:li>The former case seems to be the hot topic right now, but I think the second one might be what we actually care about?</fr:li>
      <fr:li>Maybe think about how to formulate this mathematically.</fr:li></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2587</fr:anchor><fr:addr
type="machine">#249</fr:addr><fr:route>unstable-249.xml</fr:route><fr:title
text="Tomorrow Todo's">Tomorrow Todo's</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>I have a plethora of meetings tomorrow, so I may not get too much done.</fr:li>
    <fr:li>For research,</fr:li>
    <fr:ul><fr:li><fr:strong>CRL stuff:</fr:strong> Meeting with my advisor tomorrow (scary-ish). Will hopefully have next steps after that.</fr:li>
      <fr:li><fr:strong>Compilers stuff:</fr:strong> High-priority after my meeting. Need to figure out how to get branch counts. Even if super naive (no more CPython rabbit holes).</fr:li>
      <fr:li><fr:strong>LLMs stuff:</fr:strong> Talk to group mates. Who knows where this might go.</fr:li></fr:ul>
    <fr:li>I have added another thing to the reading list: <fr:link
type="external"
href="http://www.yann-ollivier.org/rech/publs/allpolicies.pdf">Toutati et al. 2021</fr:link>. This seems to be what I was looking for. A unification of all of the successor-representation-like algorithms that have been floating around my space.</fr:li>
    <fr:li>Game-time decision whether I panic prepare stuff for my meeting / presentation, or start the probability measures section of my self-study. We shall see...</fr:li></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="References">References</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>3478</fr:anchor><fr:addr
type="user">mcleod2022</fr:addr><fr:route>mcleod2022.xml</fr:route><fr:title
text="Continual Auxiliary Task Learning">Continual Auxiliary Task Learning</fr:title><fr:taxon>Reference</fr:taxon><fr:authors /><fr:meta
name="abstract">
  Learning auxiliary tasks, such as multiple predictions about the world, can provide many benefits to reinforcement learning systems. A variety of off-policy learning algorithms have been developed to learn such predictions, but as yet there is little work on how to adapt the behavior to gather useful data for those off-policy predictions. In this work, we investigate a reinforcement learning system designed to learn a collection of auxiliary tasks, with a behavior policy learning to take actions to improve those auxiliary predictions. We highlight the inherent non-stationarity in this continual auxiliary task learning problem, for both prediction learners and the behavior learner. We develop an algorithm based on successor features that facilitates tracking under non-stationary rewards, and prove the separation into learning successor features and rewards provides convergence rate improvements. We conduct an in-depth study into the resulting multi-prediction learning system. 
  </fr:meta><fr:meta
name="doi">10.48550/arXiv.2202.11133</fr:meta><fr:meta
name="bibtex"><![CDATA[@misc{mcleod2022continualauxiliarytasklearning,
      title={Continual Auxiliary Task Learning}, 
      author={Matthew McLeod and Chunlok Lo and Matthew Schlegel and Andrew Jacobsen and Raksha Kumaraswamy and Martha White and Adam White},
      year={2022},
      eprint={2202.11133},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2202.11133}, 
}]]></fr:meta></fr:frontmatter><fr:mainmatter /><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="Context">Context</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>3479</fr:anchor><fr:addr
type="user">log-0008</fr:addr><fr:route>log-0008.xml</fr:route><fr:title
text="Daily Tracker">Daily Tracker</fr:title><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>3</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>My (somewhat) daily entries of progress / questions / thoughts. Here I will try to write daily thoughts and progress in the spirit of <fr:link
type="local"
href="richardsutton.xml"
addr="richardsutton"
title="Richard Sutton">Richard Sutton</fr:link>'s research notebook. Also my investment banking friends keep a "daily tracker" to manage workflows, so I intend to enforce a similar progress tracker on myself.</fr:p><fr:p>As daily goals, I want to structure my days as (amortized):
<fr:ul><fr:li>Self-study from textbook/course list and review anki ~2hr.</fr:li>
  <fr:li>Progress on selected research/coursework ~5-6hrs.</fr:li>
  <fr:li>Read and review paper of the week ~1hr.</fr:li>
  <fr:li>Miscellanous fiddling with this website / blog posts / interview prep ~1hr.</fr:li></fr:ul></fr:p>
  <html:hr
xmlns:html="http://www.w3.org/1999/xhtml" />
<fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2567</fr:anchor><fr:addr
type="user">log-0001</fr:addr><fr:route>log-0001.xml</fr:route><fr:title
text="11/4/2024">11/4/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>Hello world! This is my first instantiation of this daily logging thing. Here I will attempt to jot down any questions that come up in my research along with planning my daily activities of the next day. To hold my self accountable, I will log my daily accomplishments and questions.</fr:p><fr:p><fr:strong>Daily Summary:</fr:strong> Today, I focused most of my efforts on the <fr:link
type="local"
href="kak-0005.xml"
addr="kak-0005"
title="Contrastive Reinforcement Learning">Contrastive Reinforcement Learning</fr:link> blog. I was not able to finish it, but significant progress was made. I think while writing this blog I am finally starting to see how everything comes together. Ultimately, this was more of a logistical day. Since I just instatiated my more structure daily plan, hopefully we can adhere to it tomorrow.</fr:p><fr:p><fr:strong>Tomorrow Todo's:</fr:strong> With the instantiation of the new plan I will allocate my next day's activities a day in advance.</fr:p><fr:ul><fr:li>We will be starting a self-study following <fr:link
type="local"
href="richardsutton.xml"
addr="richardsutton"
title="Richard Sutton">Richard Sutton</fr:link>'s <fr:link
type="external"
href="https://drive.google.com/drive/folders/0B3w765rOKuKANmxNbXdwaE1YU1k?resourcekey=0-JZz-noRuJgogNsg1ljgV8w">CMPUT 609</fr:link> course. For tomorrow, I will go over the review questions and then start with the function approximation section of his textbook.</fr:li>
  <fr:li>For research, it is long overdue that I contribute to my weak-to-strong generalization project. There are two outstanding objectives:</fr:li>
  <fr:ul><fr:li>Finite sample analysis,</fr:li>
    <fr:li>Experiment implementation.</fr:li></fr:ul>
  I will choose / switch between these.
  <fr:li>Paper of the week will still be <fr:link
type="external"
href="gcrl">gcrl</fr:link>. I will also use this and my extra time to work on the blog post.</fr:li></fr:ul></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2569</fr:anchor><fr:addr
type="user">log-0002</fr:addr><fr:route>log-0002.xml</fr:route><fr:title
text="11/13/2024">11/13/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>It has been awhile since my last entry. Unfortunately, I had some travel among other things, but I am ready to finish the semester strong.</fr:p><fr:p><fr:strong>Daily Summary:</fr:strong> Today we finally narrowed down the scope of our compilers project. To summarize, we have implemented a CFG pass as part of Jaclang to serve as part of our LamIR to pass to a language model at runtime. However, a few questions remain:</fr:p><fr:ul><fr:li>What runtime information is important to provide in addition to the CFG, AST, etc?</fr:li>
  <fr:ul><fr:li>Currently we are focused on annotating edges of the CFG with visitation counts as they happen at runtime.</fr:li>
    <fr:li>As an implementation detail, is there a better way then <fr:code>sys.settrace</fr:code> to get runtime information without having to modify CPython source code?</fr:li></fr:ul>
    <fr:li>How do we represent this representation in natural language in order for the LLM to provide meaningful results?</fr:li>
    <fr:li>What is a meaningful result?</fr:li>
    <fr:ul><fr:li>Currently, we are interested in smart asserts, but ideally some code optimization can be performed.</fr:li></fr:ul></fr:ul><fr:p><fr:strong>Tomorrow Todo's:</fr:strong></fr:p><fr:ul><fr:li>In preparation for MATH 626 next semester, I need to brush up on probability. To do so, I will be following along with <fr:link
type="external"
href="https://www.colorado.edu/amath/sites/default/files/attached-files/billingsley.pdf">Probability and Measure</fr:link> by Billingsley.</fr:li>
  <fr:li>For research,</fr:li>
  <fr:ul><fr:li>Must get contrastive RL experiments up and running,</fr:li>
    <fr:li>If that happens I plan to set up dumping runtime info in Jaclang.</fr:li>
    <fr:li>Also I have a scheduled meeting with AMD advisors for GPU project. We will see what comes of this.</fr:li></fr:ul>
  <fr:li>Paper of the week will still be <fr:link
type="external"
href="gcrl">gcrl</fr:link>. Any other extra/break time will be towards blog post.</fr:li></fr:ul></fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2571</fr:anchor><fr:addr
type="user">log-0003</fr:addr><fr:route>log-0003.xml</fr:route><fr:title
text="11/14/2024">11/14/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>This day did not quite go to plan. The contrastive RL repo is not exactly how imagined it...</fr:p>
  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2573</fr:anchor><fr:addr
type="machine">#252</fr:addr><fr:route>unstable-252.xml</fr:route><fr:title
text="Daily Summary">Daily Summary</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    <fr:strong>GPU Project:</fr:strong>
    <fr:ul><fr:li>Have GPU kernel for part of chaining algorithm. Makes a CPU call for another part</fr:li>
      <fr:ul><fr:li>Need to write a kernel for a naturally sequential DP.</fr:li>
        <fr:li>My initial impression is just how to reuse any memory accesses that have been done for the current GPU kernel.</fr:li></fr:ul>
      <fr:li>Key question is does even a naive kernel implementation speed up the overall program due to the eliminated memory transfer between GPU and CPU?</fr:li></fr:ul>
    <fr:strong>Contrastive RL:</fr:strong>
    <fr:ul><fr:li>Question is how to do contrastive RL in a lifelong setting? i.e. non-episodic and potentially changing reward functions.</fr:li>
      <fr:li>Have a pretty good idea how to implement the ant gather environment. However, current setup returns object positions.</fr:li>
      <fr:ul><fr:li>If there are a lot (potentially infinite) apples / bombs this will not work.</fr:li>
          <fr:li>Need to modify so observations are images, but this makes problem significantly harder.</fr:li></fr:ul></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2575</fr:anchor><fr:addr
type="machine">#253</fr:addr><fr:route>unstable-253.xml</fr:route><fr:title
text="Tomorrow Todo's">Tomorrow Todo's</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
<fr:ul><fr:li>Might not have time for self-study tomorrow. It is a packed day.</fr:li>
  <fr:li>For research,</fr:li>
  <fr:ul><fr:li><fr:strong>CRL stuff:</fr:strong> Render ant gather environment. Hopefully, before compilers meeting.</fr:li>
    <fr:li><fr:strong>Compilers stuff:</fr:strong> Have meeting. Need actionable goals for runtime information logging.</fr:li>
    <fr:li><fr:strong>LLMs stuff:</fr:strong> After group meeting, must make slides on weak-to-strong. Look at new version of paper.</fr:li></fr:ul>
  <fr:li>If I somehow have extra time, then continue with probability self study. Ideally, I get through the background chapter by Monday. We want to get to probability measures to do probability!</fr:li>
  <fr:ul><fr:li>It seems it may also be a good idea to get some background with discrete stochastic processes, so I may concurrently follow along an MIT courseware course. TBD.</fr:li></fr:ul></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2577</fr:anchor><fr:addr
type="user">log-0004</fr:addr><fr:route>log-0004.xml</fr:route><fr:title
text="11/16/2024">11/16/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>I am currently on a run of bad productivity days. Hopefully, this will be resolved with a lighter exercise load next week.</fr:p>
  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2579</fr:anchor><fr:addr
type="machine">#250</fr:addr><fr:route>unstable-250.xml</fr:route><fr:title
text="Daily Summary">Daily Summary</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    <fr:strong>Contrastive RL:</fr:strong> Today, I did spend a bit of time on this project. Mainly, I have been accumulating useful tips from productive researchers, and they recommend not rushing to publish but rather deeply understanding your field first. Due to this, I have decided to take a brief step back and survey the field a bit.
    <fr:ul><fr:li>I quickly went over a parallel line of work based on Laplacian representations of transition dynamics. It seems there is an explicit correspondence between these approaches and the successor representation I have grown accustomed to. A question I plan to explore is what advantages one approach offers over the other? Maybe there is a slick way to compute one efficiently?</fr:li>
      <fr:li>I also have come to the realization that I do not need to implement the ant gather environment in its entirety right away. Just re-using the ant ball environment and respawning the ball when it is reached should be enough?</fr:li></fr:ul>
<fr:strong>Weak-to-strong Generalization:</fr:strong> Unfortunately, this is what I spent most of my time on today. We have an upcoming presentation on the topic and so I obviously obsessively have tried to understand everything that may come up as a question.
<fr:ul><fr:li>The prevailing result of today is that our previous formulation was not very good. (Exciting I know)</fr:li>
    <fr:li>My main takeaway is that if we assume a latent concept space i.e. 
<fr:tex
display="block"><![CDATA[\mathrm {LLM}(Y \mid  X) = \int _{\Theta } f(Y \mid  X, \theta ) p(\theta  \mid  X) d\theta ]]></fr:tex>
    In the previous formulation, the ICL task can only correspond to <fr:strong>one</fr:strong> <fr:tex
display="inline"><![CDATA[\theta ]]></fr:tex>. This is because then if we assume ICL is doing bayesian update it can identify <fr:tex
display="inline"><![CDATA[\theta ]]></fr:tex>.</fr:li>
    <fr:ul><fr:li>Not sold on if this is true.</fr:li>
        <fr:li>Main question is what do they mean by overlap?</fr:li>
        <fr:ul><fr:li>Does each <fr:tex
display="inline"><![CDATA[q_i(Y \mid  X) = q(Y \mid  X, \theta _i)]]></fr:tex> have non-overlapping output space?</fr:li>
            <fr:li>Or are they referring to the assumption that the target task is a single <fr:tex
display="inline"><![CDATA[\theta _i]]></fr:tex>?</fr:li></fr:ul></fr:ul></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2581</fr:anchor><fr:addr
type="machine">#251</fr:addr><fr:route>unstable-251.xml</fr:route><fr:title
text="Tomorrow Todo's">Tomorrow Todo's</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
<fr:ul><fr:li>I intend to be a probabilist next semester, so I must refresh probabliity background ASAP. Aim for 1-2hrs of probability book.</fr:li>
  <fr:li>For research,</fr:li>
  <fr:ul><fr:li><fr:strong>CRL stuff:</fr:strong> Implement non-stationary ant ball. Hopefully, get some sort of experiment running.</fr:li>
    <fr:li><fr:strong>Compilers stuff:</fr:strong> Might be meeting with group tomorrow?</fr:li>
    <fr:li><fr:strong>LLMs stuff:</fr:strong> If left over time, then dive into alternative interesting formulations (unlikely).</fr:li></fr:ul>
  <fr:li>As my next reading endeavour, I intend to deeply understand the successor features survey by Machado and Doina. This will probably be a paper of the month as I cannot possibly digest the 70 page behemoth in the next week.</fr:li>
  <fr:li>As another thing todo, is get better at writing these todo's. Ideally, they will be much more actionable as I continue making these logs. I guess we'll see.</fr:li></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2583</fr:anchor><fr:addr
type="user">log-0005</fr:addr><fr:route>log-0005.xml</fr:route><fr:title
text="11/18/2024">11/18/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>Today we kind of got back on track.</fr:p>
  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2585</fr:anchor><fr:addr
type="machine">#248</fr:addr><fr:route>unstable-248.xml</fr:route><fr:title
text="Daily Summary">Daily Summary</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    <fr:strong>Contrastive RL:</fr:strong> As a way to avoid struggling with mujoco, I re-immersed myself in the relevant literature. I had a few takeaways:
    <fr:ul><fr:li>I took a look back at the <fr:link
type="local"
href="mcleod2022.xml"
addr="mcleod2022"
title="Continual Auxiliary Task Learning">Continual Auxiliary Task Learning</fr:link> paper. I still really want to implement a system that puts everything together. Namely,</fr:li>
      <fr:ul><fr:li>In this paper, they do not learn the cumulants that they use to compute the successor features.</fr:li>
          <fr:li>Also, is a continual optimizer enough for non-stationary MDPs when learning cumulants?</fr:li></fr:ul>
        <fr:li>Regarding implementation details for the Contrastive RL stuff. It seems the first priority should actually be implementing the hierarchical policy.</fr:li>
        <fr:ul><fr:li>Currently, the repo is set up to randomly select goals and see how well the goal-conditioned policy can reach them. This is basically the extent of experimentation needed without the hierarchical policy.</fr:li></fr:ul>
      <fr:li>I did come across an alternative successor-feature like apprach that I want to take a closer look at: the Forward-Backward representation <fr:link
type="external"
href="https://openreview.net/pdf?id=MYEap_OcQI">Toutati et al. 2023</fr:link>, <fr:link
type="external"
href="http://www.yann-ollivier.org/rech/publs/allpolicies.pdf">Toutati et al. 2021</fr:link>, <fr:link
type="external"
href="https://arxiv.org/pdf/2101.07123">Blier et al. 2021</fr:link>. Initial impressions:</fr:li>
      <fr:ul><fr:li>Seems to be learned in a very similar manner to the successor feature stuff.</fr:li>
          <fr:li>Re-parametrization avoids converging to trivial 0 solution.</fr:li>
          <fr:li>Experimentally, seems way better than contrastive (at least for zero shot RL).</fr:li></fr:ul></fr:ul>
<fr:strong>Weak-to-strong Generalization:</fr:strong> I finished up my slides for our presentation tomorrow.
<fr:ul><fr:li>I have sufficiently confused myself on what weak-to-strong generalization even means. Is it</fr:li>
    <fr:ol><fr:li>Correctly answering things that the weak model got incorrect? or</fr:li>
        <fr:li>Generalizing correct answers on easier tasks to harder tasks?</fr:li></fr:ol>
      <fr:li>The former case seems to be the hot topic right now, but I think the second one might be what we actually care about?</fr:li>
      <fr:li>Maybe think about how to formulate this mathematically.</fr:li></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2587</fr:anchor><fr:addr
type="machine">#249</fr:addr><fr:route>unstable-249.xml</fr:route><fr:title
text="Tomorrow Todo's">Tomorrow Todo's</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>I have a plethora of meetings tomorrow, so I may not get too much done.</fr:li>
    <fr:li>For research,</fr:li>
    <fr:ul><fr:li><fr:strong>CRL stuff:</fr:strong> Meeting with my advisor tomorrow (scary-ish). Will hopefully have next steps after that.</fr:li>
      <fr:li><fr:strong>Compilers stuff:</fr:strong> High-priority after my meeting. Need to figure out how to get branch counts. Even if super naive (no more CPython rabbit holes).</fr:li>
      <fr:li><fr:strong>LLMs stuff:</fr:strong> Talk to group mates. Who knows where this might go.</fr:li></fr:ul>
    <fr:li>I have added another thing to the reading list: <fr:link
type="external"
href="http://www.yann-ollivier.org/rech/publs/allpolicies.pdf">Toutati et al. 2021</fr:link>. This seems to be what I was looking for. A unification of all of the successor-representation-like algorithms that have been floating around my space.</fr:li>
    <fr:li>Game-time decision whether I panic prepare stuff for my meeting / presentation, or start the probability measures section of my self-study. We shall see...</fr:li></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2589</fr:anchor><fr:addr
type="user">log-0006</fr:addr><fr:route>log-0006.xml</fr:route><fr:title
text="11/20/2024">11/20/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>I am still hitting an afternoon wall. I have yet to put a full day together in awhile, but the waking up early and working has helped a little bit.</fr:p>
  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2591</fr:anchor><fr:addr
type="machine">#246</fr:addr><fr:route>unstable-246.xml</fr:route><fr:title
text="Daily Summary">Daily Summary</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:p><fr:strong>Probability Theory:</fr:strong> Upon waking up, I seem to struggle to immediately go into coding mode. To still be productive, I have instituted a self-study or paper reading upon waking up. For some reason this is more manageable to me? Anyways, I have made it through the second section of <fr:link
type="local"
href="billingsley1986.xml"
addr="billingsley1986"
title="Probability and Measure">Probability and Measure</fr:link>, where we defined probabilty measures. I do think carefully going through this without worrying about problem sets, etc. has allowed me to gain a bit more intuition into what is going on.</fr:p>

  <fr:p><fr:strong>Weak-to-strong Generalization:</fr:strong> Upon reading the linear probing paper <fr:link
type="external"
href="https://arxiv.org/pdf/2202.10054">Kumar et al. 2022</fr:link> and Mihir's wonderful presentation, I understand better what their claims are and have kind of shifted focus.

    <fr:ul><fr:li>In the linear probing case, they assume the in distribution and out of distribution still come from the same "sample space" in some sense.</fr:li>
        <fr:li>They also are all correctly labeled unlike in weak-to-strong.</fr:li>
        <fr:li>To me, this applies better to easy-to-hard generalization, so we are now exploring this direction instead.</fr:li>
        <fr:li>The main question now is how to theoretically represent an "easy" and hard question? Along with how to represent the "latent knowledge" that allows the model to generalize from easy-to-hard?</fr:li>
        <fr:li>Need to setup experiments to test linear probing vs. fine-tuning in easy-to-hard.</fr:li>
        <fr:li>Existing papers only do linear probing vs. LoRA.</fr:li></fr:ul></fr:p>
<fr:p><fr:strong>Ghost in the shell:</fr:strong> This project has also started to take off a little bit. I have been tasked with implementing the python tracer to provide profile information to our LaMIR.
<fr:ul><fr:li>I am still feeling a bit ambitious and want to do this in C with CPython. However, my group is more intent on just getting something working, which I can understand.</fr:li>
    <fr:li>Need to better gauge how difficult a C tracer would be before I decide.</fr:li></fr:ul></fr:p>
</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2593</fr:anchor><fr:addr
type="machine">#247</fr:addr><fr:route>unstable-247.xml</fr:route><fr:title
text="Tomorrow Todo's">Tomorrow Todo's</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>Section 3 of <fr:link
type="local"
href="billingsley1986.xml"
addr="billingsley1986"
title="Probability and Measure">Probability and Measure</fr:link> seems a bit dense. Finish construction of extension and see how we feel.</fr:li>
    <fr:li>Time to deeply understand contrastive RL. In particular, how Q-function comes from contrastive loss</fr:li>
    <fr:ul><fr:li>If in the mood, try to understand <fr:link
type="local"
href="nachum2019.xml"
addr="nachum2019"
title="Near Optimal Representation Learning for Hierarchical Reinforcement Learning">Near Optimal Representation Learning for Hierarchical Reinforcement Learning</fr:link> connection to contrastive RL</fr:li></fr:ul>
    <fr:li>Otherwise, pick one of tracer work / linear probing work to make some progress on.</fr:li></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter /></fr:tree><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2595</fr:anchor><fr:addr
type="user">log-0007</fr:addr><fr:route>log-0007.xml</fr:route><fr:title
text="11/21/2024">11/21/2024</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:meta
name="author">false</fr:meta></fr:frontmatter><fr:mainmatter><fr:p>Not a maximally productive day but good progress was made on (almost?) every project.</fr:p>
  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2597</fr:anchor><fr:addr
type="machine">#244</fr:addr><fr:route>unstable-244.xml</fr:route><fr:title
text="Daily Summary">Daily Summary</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:p><fr:strong>Probability Theory:</fr:strong> I am having a surprisingly good time learning this compared to my experience in undergrad. Today, I finished and thorougly understood the extension of a measure to the <fr:tex
display="inline"><![CDATA[\sigma ]]></fr:tex>-algebra induced by the outer measure. I left the uniqueness for the next session. I guess the only outstanding question I had was 
    <fr:ul><fr:li>Why do we need to impose the extra condition that we need the set to satisfy <fr:tex
display="inline"><![CDATA[P^*(A \cap  E) + P^*(A^c \cap  E) = P^*(E)]]></fr:tex> for every <fr:tex
display="inline"><![CDATA[E \subset  \Omega ]]></fr:tex> vs. just taking <fr:tex
display="inline"><![CDATA[E = \Omega ]]></fr:tex>?</fr:li></fr:ul></fr:p>

  <fr:p><fr:strong>Contrastive RL:</fr:strong> Today was big for my understanding along with an interesting new direction.
    <fr:ul><fr:li>I went over both the original <fr:link
type="local"
href="gutmann2012.xml"
addr="gutmann2012"
title="Noise-contrastive Estimation">NCE</fr:link> and <fr:link
type="local"
href="vandenOord2018.xml"
addr="vandenOord2018"
title="Contrastive Predictive Decoding">InfoNCE</fr:link> papers to better understand the non-RL versions.</fr:li>
      <fr:li>Finally have kind of understood, where the <fr:tex
display="inline"><![CDATA[Q]]></fr:tex>-function comes from in <fr:link
type="local"
href="eysenbach2023.xml"
addr="eysenbach2023"
title="Constrastive Learning as Goal Conditioned Reinforcement Learning">Constrastive Learning as Goal Conditioned Reinforcement Learning</fr:link> even though they do not provide proof of the Lemma that claims it.</fr:li>
      <fr:ul><fr:li>In the <fr:link
type="local"
href="gutmann2012.xml"
addr="gutmann2012"
title="Noise-contrastive Estimation">Noise-contrastive Estimation</fr:link> paper, they show that their objective will converge to the distribution that generated the data <fr:tex
display="inline"><![CDATA[p(x)]]></fr:tex>. In <fr:link
type="local"
href="eysenbach2023.xml"
addr="eysenbach2023"
title="Constrastive Learning as Goal Conditioned Reinforcement Learning">Constrastive Learning as Goal Conditioned Reinforcement Learning</fr:link>, they want to learn the discounted state occupancy measure. To make this their <fr:tex
display="inline"><![CDATA[p(x)]]></fr:tex>, 
          <fr:ol><fr:li>they take their "positive" examples as drawn from the state occupancy (turns out to do this is not that hard).</fr:li>
            <fr:li>they just sample their negative examples uniformly.</fr:li></fr:ol>
          <fr:li>Need to look a little more at <fr:tex
display="inline"><![CDATA[Q]]></fr:tex>-function is state discounted probability proof. Why is it not just linearity of expectation / Fubini? Inner series is clearly convergent? Probably related to policy stuff I need to get better at.</fr:li></fr:li></fr:ul>
        <fr:li>An interesting idea that came up is to apply goal-conditioned RL to safe RL. Namely, we can discourage the visitation of unsafe states by considering <fr:tex
display="inline"><![CDATA[Q(s, a, \text {unsafe})]]></fr:tex></fr:li>
        <fr:ul><fr:li>Take <fr:tex
display="inline"><![CDATA[\pi  \in  \arg \max _{\pi } Q(s, \pi (s), g) - \lambda (\delta ) Q(s, \pi (s), \text {obstacle})]]></fr:tex>, or</fr:li>
            <fr:li>take <fr:tex
display="inline"><![CDATA[\pi  \in  \arg \max _{\pi } Q(s, \pi (s), g)]]></fr:tex>, such that <fr:tex
display="inline"><![CDATA[Q(s, \pi (s), \text {obstacle}) < \epsilon ]]></fr:tex>.</fr:li></fr:ul></fr:ul></fr:p>
<fr:p><fr:strong>Ghost in the shell:</fr:strong> New ideas have arisen to turn this course project into a research project.
<fr:ul><fr:li>Professors introduce the concept of "phase detection" from microarchitecture.</fr:li>
    <fr:li>It seems that this area is concerned with detecting how inputs may influence things like hot paths and detecting when this is going to occur.</fr:li>
    <fr:li>These methods all seems to choose metrics and algorithms for these metrics arbitrarily.</fr:li>
    <fr:li>Can we pass a superset of all these metrics to an LLM and have it detect phase changes automatically?</fr:li></fr:ul></fr:p>
</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>2599</fr:anchor><fr:addr
type="machine">#245</fr:addr><fr:route>unstable-245.xml</fr:route><fr:title
text="Tomorrow Todo's">Tomorrow Todo's</fr:title><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>I want to start <fr:link
type="local"
href="jiang2024.xml"
addr="jiang2024"
title="Reinforcement Learning: Theory and Algorithms">Reinforcement Learning: Theory and Algorithms</fr:link> tomorrow, taking a short break from very abstract / rigorous mathematics.</fr:li>
    <fr:li>Focus tomorrow is getting profiling up and running.</fr:li>
    <fr:ul><fr:li>By EOD, need to have edges of CFG filled with visitation frequencies.</fr:li></fr:ul>
    <fr:li>If extra time, finish / work on <fr:link
type="local"
href="kak-0005.xml"
addr="kak-0005"
title="Contrastive Reinforcement Learning">Contrastive Reinforcement Learning</fr:link> blog post with newfound knowledge.</fr:li></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:backmatter></fr:tree>