<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1860</fr:anchor><fr:addr
type="user">zeng2025simplerl</fr:addr><fr:route>zeng2025simplerl.xml</fr:route><fr:title
text="7B model and 8K examples: Emerging reasoning with reinforcement learning is both effective and efficient">7B model and 8K examples: Emerging reasoning with reinforcement learning is both effective and efficient</fr:title><fr:taxon>Reference</fr:taxon><fr:date><fr:year>2025</fr:year></fr:date><fr:authors><fr:author>Weihao Zeng</fr:author><fr:author>Yuzhen Huang</fr:author><fr:author>Wei Liu</fr:author><fr:author>Keqing He</fr:author><fr:author>Qian Liu</fr:author><fr:author>Zejun Ma</fr:author><fr:author>Junxian He</fr:author></fr:authors><fr:meta
name="external">https://hkust-nlp.notion.site/simplerl-reason</fr:meta><fr:meta
name="bibtex"><![CDATA[@misc{zeng2025simplerl,
 title = {7B Model and 8K Examples: Emerging Reasoning with Reinforcement
Learning is Both Effective and Efficient},
 author = {Weihao Zeng and Yuzhen Huang and Wei Liu and Keqing He and Qian Liu
and Zejun Ma and Junxian He},
 year = {2025},
 howpublished = {\url{https://hkust-nlp.notion.site/simplerl-reason}},
 note = {Notion Blog}
}]]></fr:meta></fr:frontmatter><fr:mainmatter /><fr:backmatter><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="Backlinks">Backlinks</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>1868</fr:anchor><fr:addr
type="user">kak-003D</fr:addr><fr:route>kak-003D.xml</fr:route><fr:title
text="Deepseek v1 through R1: RL is back!">Deepseek v1 through R1: RL is back!</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>In this blog, we will aim to understand the key contributions of <fr:link
type="local"
href="deepseekai2025deepseekr1incentivizingreasoningcapability.xml"
addr="deepseekai2025deepseekr1incentivizingreasoningcapability"
title="DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning">DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning</fr:link>. It will serve as the complement to my group meeting presentation possibly consisting of more in-depth explanations. Time permitting, we might go over the engineering innovations introduced in <fr:link
type="local"
href="deepseekai2024deepseekv3technicalreport.xml"
addr="deepseekai2024deepseekv3technicalreport"
title="DeepSeek-V3 technical report">DeepSeek-V3 technical report</fr:link>.</fr:p>
  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>452</fr:anchor><fr:addr
type="machine">#292</fr:addr><fr:route>unstable-292.xml</fr:route><fr:title
text="Background">Background</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    By request of my advisor, I will cover the basics of LLMs prior to the innovations in the Deepseek lineage. For those familiar with LLMs, please skip this section.
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>454</fr:anchor><fr:addr
type="user">kak-004J</fr:addr><fr:route>kak-004J.xml</fr:route><fr:title
text="Word Embeddings">Word Embeddings</fr:title><fr:date><fr:year>2025</fr:year><fr:month>2</fr:month><fr:day>3</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tex
display="block"><![CDATA[\mathrm {Tok}(\mathbf {x})=\begin {bmatrix} 132\\ 17 \\ 87\\ 83\\ 184\end {bmatrix}]]></fr:tex></fr:mainmatter><fr:backmatter /></fr:tree>
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>455</fr:anchor><fr:addr
type="user">kak-004G</fr:addr><fr:route>kak-004G.xml</fr:route><fr:title
text="Self-Attention">Self-Attention</fr:title><fr:date><fr:year>2025</fr:year><fr:month>2</fr:month><fr:day>1</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:p>TLDR: Learned weighting of token embeddings. Essentially, learning which words to "attend" to in the input sequence. Have matrices
<fr:tex
display="inline"><![CDATA[\mathbf {Q} = \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {q}^{(1)} & \text {---}   \end {bmatrix} \\   \vdots  \\   \begin {bmatrix}     \text {---} & \mathbf {q}^{(n)} & \text {---}   \end {bmatrix} \end {bmatrix} \in  \mathbb {R}^{n \times  d_q}]]></fr:tex>, 
<fr:tex
display="inline"><![CDATA[ \mathbf {K} = \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {k}^{(1)} & \text {---}   \end {bmatrix} \\   \vdots  \\   \begin {bmatrix}     \text {---} & \mathbf {k}^{(n)} & \text {---}   \end {bmatrix} \end {bmatrix} \in  \mathbb {R}^{n \times  d_k} ]]></fr:tex>
<fr:tex
display="inline"><![CDATA[ \mathbf {V} = \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {v}^{(1)} & \text {---}   \end {bmatrix} \\   \vdots  \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(n)} & \text {---}   \end {bmatrix} \end {bmatrix} \in  \mathbb {R}^{n \times  d_v} ]]></fr:tex></fr:p><fr:p><fr:strong>Intuition 1:</fr:strong> Convex re-weighting of input tokens.
  Note that
<fr:tex
display="block"><![CDATA[ \begin {align*}   \begin {bmatrix}     p_1 & p_2 & p_3   \end {bmatrix} \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {v}^{(1)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(2)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(3)} & \text {---}   \end {bmatrix}   \end {bmatrix} = p_1 \mathbf {v}^{(1)} + p_2 \mathbf {v}^{(2)} + p_3 \mathbf {v}^{(3)} \end {align*}   ]]></fr:tex>
<fr:tex
display="block"><![CDATA[ \begin {align*}   \begin {bmatrix}     p_{11} & 0 & 0 \\     p_{21} & p_{22} & 0 \\     p_{31} & p_{32} & p_{33}   \end {bmatrix} \begin {bmatrix}   \begin {bmatrix}     \text {---} & \mathbf {v}^{(1)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(2)} & \text {---}   \end {bmatrix} \\   \begin {bmatrix}     \text {---} & \mathbf {v}^{(3)} & \text {---}   \end {bmatrix}   \end {bmatrix} =    \begin {bmatrix}   p_{11} \mathbf {v}^{(1)}  \\   p_{21} \mathbf {v}^{(1)} + p_{22} \mathbf {v}^{(2)} \\   p_{31} \mathbf {v}^{(1)} + p_{32} \mathbf {v}^{(2)} + p_{33} \mathbf {v}^{(3)}   \end {bmatrix} \end {align*}   ]]></fr:tex>
  <fr:strong>Intuition 2:</fr:strong> Context dependent re-weighting.
      If <fr:tex
display="inline"><![CDATA[\mathbf {p} = \mathbb {S}(\mathbf {Q} \mathbf {K}^T)]]></fr:tex> then
      <fr:tex
display="block"><![CDATA[         \begin {align*}           p_{ij} = \frac {\mathbf {q}^{(i)} \cdot  \mathbf {k}^{(j)}}{\sum _{j} \mathbf {q}^{(i)} \cdot  \mathbf {k}^{(j)}}         \end {align*}       ]]></fr:tex></fr:p>
   
   <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>457</fr:anchor><fr:addr
type="machine">#264</fr:addr><fr:route>unstable-264.xml</fr:route><fr:taxon>Example</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>2</fr:month><fr:day>1</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    Suppose that <fr:tex
display="inline"><![CDATA[\mathbf {x} = \text {I play with the ball}]]></fr:tex>. Then 
<fr:tex
display="block"><![CDATA[     \begin {align*}       \mathbf {x}^{(5)} = \mathrm {Embed}(\text {``ball"})     \end {align*}   ]]></fr:tex>
  A feasible query for "ball" would be a verb describing the action of the ball, so maybe
  <fr:tex
display="block"><![CDATA[   \begin {align*}       W_q \mathbf {x}^{(5)} = \mathrm {Embed}(\text {``play"})   \end {align*}   ]]></fr:tex>
  and a key for "play" would be what you are playing with like a ball, so 
  <fr:tex
display="block"><![CDATA[   \begin {align*}       W_k \mathbf {x}^{(2)} = \mathrm {Embed}(\text {``ball"})   \end {align*}   ]]></fr:tex>
  i.e.
<fr:tex
display="block"><![CDATA[   \begin {align*}     \mathrm {Query}(\text {``quantum"}) \cdot  \mathrm {Key}(\text {``mechanics"}) \approx      ||\mathrm {Query}(\text {``quantum"})|| \cdot  ||\mathrm {Key}(\text {``mechanics"})||   \end {align*} ]]></fr:tex>

</fr:mainmatter><fr:backmatter /></fr:tree>
 
<fr:p><fr:tex
display="block"><![CDATA[   \begin {align*} \left [\mathbb {S}(\mathbf {Q}\mathbf {K}^T)\right ]_{4} &= \mathbb {S}\left (\begin {bmatrix} \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(1)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(2)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(3)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(4)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(5)} & \mathbf {q}^{(4)} \cdot  \mathbf {k}^{(6)} \end {bmatrix} \right ) \\ &= \begin {bmatrix} 0 & 0.2 & 0.3 & 0.5 & 0 & 0 \end {bmatrix}   \end {align*} ]]></fr:tex>
<fr:tex
display="block"><![CDATA[ \left [\mathbb {S}(\mathbf {Q}\mathbf {K}^T)\right ]_{4} \mathbf {V} = 0.2 \mathbf {v}^{(2)} + 0.3 \mathbf {v}^{(3)} + 0.5 \mathbf {v}^{(5)} ]]></fr:tex></fr:p></fr:mainmatter><fr:backmatter /></fr:tree>
    
  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>459</fr:anchor><fr:addr
type="machine">#291</fr:addr><fr:route>unstable-291.xml</fr:route><fr:title
text="RLHF">RLHF</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
<fr:tex
display="block"><![CDATA[\mathrm {loss}\left (\phi \right )=E_{\left (x,y\right )\sim  D_{\pi _{\phi }^{\mathrm {RL}}}}\left [r_\theta (x,y)-\beta \log \left (\pi _{\phi }^{\mathrm {RL}}(y\mid  x)/\pi ^{\mathrm {SFT}}(y\mid  x)\right )\right ] + \gamma  E_{x\sim  D_{\mathrm {pretrain}}}\left [\log (\pi _{\phi }^{\mathrm {RL}}(x))\right ]]]></fr:tex>
      </fr:mainmatter><fr:backmatter /></fr:tree>
  

</fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>461</fr:anchor><fr:addr
type="machine">#293</fr:addr><fr:route>unstable-293.xml</fr:route><fr:title
text="Deepseek v2">Deepseek v2</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    Paper 
  </fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>463</fr:anchor><fr:addr
type="machine">#294</fr:addr><fr:route>unstable-294.xml</fr:route><fr:title
text="Deepseek v3">Deepseek v3</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
TODO. Kinda wanna look into the architectural / training innovations from this paper.
  </fr:mainmatter><fr:backmatter /></fr:tree>
  

  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>465</fr:anchor><fr:addr
type="machine">#298</fr:addr><fr:route>unstable-298.xml</fr:route><fr:title
text="Deepseek R1">Deepseek R1</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>


  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>467</fr:anchor><fr:addr
type="machine">#295</fr:addr><fr:route>unstable-295.xml</fr:route><fr:title
text="How is R1 different then previous iterations of models?">How is R1 different then previous iterations of models?</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>In R1-Zero, they do <fr:strong>ZERO</fr:strong> SFT on the base model - directly apply reinforcement learning.</fr:li>
    <fr:li>Use PPO like policy optimization but do <fr:strong>NOT</fr:strong> learn a reward model.</fr:li>
    <fr:ul><fr:li>Use very simple reward: 
        <fr:ul><fr:li><fr:tex
display="inline"><![CDATA[+1]]></fr:tex> for correct answer</fr:li> 
          <fr:li><fr:tex
display="inline"><![CDATA[-0.5]]></fr:tex> for incorrect answer</fr:li> 
          <fr:li><fr:tex
display="inline"><![CDATA[-1]]></fr:tex> for inability to answer.</fr:li></fr:ul></fr:li></fr:ul></fr:ul>
</fr:mainmatter><fr:backmatter /></fr:tree>
  


<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>469</fr:anchor><fr:addr
type="user">kak-003X</fr:addr><fr:route>kak-003X.xml</fr:route><fr:title
text="Group Relative Policy Optimization">Group Relative Policy Optimization</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>Traditional actor critic RL algorithms, require training both an actor and a critic (as the name implies). Typically, these components are both of equal size. In the field of RL, this is non-problematic because models are typically rather small (at least in comparison to LLMs).
In <fr:link
type="local"
href="shao2024deepseekmathpushinglimitsmathematical.xml"
addr="shao2024deepseekmathpushinglimitsmathematical"
title="DeepSeekMath: Pushing the limits of mathematical reasoning in open language models">DeepSeekMath: Pushing the limits of mathematical reasoning in open language models</fr:link></fr:p>
  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>470</fr:anchor><fr:addr
type="machine">#288</fr:addr><fr:route>unstable-288.xml</fr:route><fr:title
text="Math">Math</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter>
  <fr:tex
display="block"><![CDATA[     \begin {align*}     {\mathcal {J}}_{\mathrm {GRPO}}(\theta )&= \mathbb {E}[q\sim  P(Q),\{o_{i}\}_{i=1}^{G}\sim \pi _{\theta _{o l d}}(O|q)] \\     &= \frac {1}{G}\sum _{i=1}^{G}\left (\operatorname *{min}\left (\frac {\pi _{\theta }(o_{i}|q)}{\pi _{\theta _{o d}}(o_{i}|q)}A_{i},\operatorname *{clip}\left (\frac {\pi _{\theta }(o_{i}|q)}{\pi _{\theta _{o d d}}(o_{i}|q)},1-\varepsilon ,1+\varepsilon \right )A_{i}\right )-\beta \mathbb {D}_{K L}\left (\pi _{\theta }||\pi _{r e f}\right )\right )     \end {align*}   ]]></fr:tex>
  where
  <fr:tex
display="block"><![CDATA[         \mathbb {D}_{\mathrm {K L}}\left (\pi _{\theta }||\pi _{\mathrm {ref}}\right )=\frac {\pi _{\mathrm {ref}}(o_{i}|q)}{\pi _{\theta }(o_{i}|q)}-\log \frac {\pi _{\mathrm {ref}}(o_{i}|q)}{\pi _{\theta }(o_{i}|q)}-1     ]]></fr:tex>
    The astute RL reader will notice this is essentially <fr:link
type="local"
href="schulman2017proximalpolicyoptimizationalgorithms.xml"
addr="schulman2017proximalpolicyoptimizationalgorithms"
title="Proximal policy optimization algorithms">PPO</fr:link>.
    The key distinction here is that the advantage <fr:tex
display="inline"><![CDATA[A_i]]></fr:tex> is not computed using a critic model. Instead, 
<fr:tex
display="block"><![CDATA[A_{i}=\frac {r_{i}-\mathrm {mean}(\{r_{1},r_{2},\cdots ,r_{G}\})}{\mathrm {std}(\{r_{1},r_{2},\cdots ,r_{G}\})}.]]></fr:tex>
</fr:mainmatter><fr:backmatter /></fr:tree>
  
</fr:mainmatter><fr:backmatter /></fr:tree>


  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>471</fr:anchor><fr:addr
type="machine">#296</fr:addr><fr:route>unstable-296.xml</fr:route><fr:title
text="Post-training">Post-training</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
    <fr:ul><fr:li><fr:em>Reinforcement Learning for all Scenarios:</fr:em> Seems like they do RLHF after the pure RL stage.</fr:li>
        <fr:ul><fr:li>Do traditional helpfulness harmfulness RLHF with trained reward model.</fr:li></fr:ul></fr:ul>
  </fr:mainmatter><fr:backmatter /></fr:tree>
  



  
    <fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>473</fr:anchor><fr:addr
type="machine">#297</fr:addr><fr:route>unstable-297.xml</fr:route><fr:title
text="Distilling Models with R1">Distilling Models with R1</fr:title><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>27</fr:day></fr:date><fr:authors><fr:author><fr:link
type="local"
href="kellenkanarios.xml"
addr="kellenkanarios"
title="Kellen Kanarios">Kellen Kanarios</fr:link></fr:author></fr:authors></fr:frontmatter><fr:mainmatter>
  <fr:ul><fr:li>To distill, they do only SFT with R1 generated COT.</fr:li>
      <fr:li>They show that distillation outperforms doing pure RL approach on smaller model</fr:li>
      <fr:ul><fr:li>Seems contradictory to <fr:link
type="local"
href="zeng2025simplerl.xml"
addr="zeng2025simplerl"
title="7B model and 8K examples: Emerging reasoning with reinforcement learning is both effective and efficient">7B model and 8K examples: Emerging reasoning with reinforcement learning is both effective and efficient</fr:link></fr:li></fr:ul></fr:ul>
  </fr:mainmatter><fr:backmatter /></fr:tree>
  


</fr:mainmatter><fr:backmatter /></fr:tree>
  

  <html:hr
xmlns:html="http://www.w3.org/1999/xhtml" />
<html:script
xmlns:html="http://www.w3.org/1999/xhtml"
src="https://utteranc.es/client.js"
repo="kkanarios32/website-comments"
issue-term="pathname"
theme="boxy-light"
crossorigin="anonymous"
async="" /></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:backmatter></fr:tree>