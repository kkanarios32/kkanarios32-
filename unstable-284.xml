<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>882</fr:anchor><fr:addr
type="machine">#284</fr:addr><fr:route>unstable-284.xml</fr:route><fr:taxon>Remark</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter>
		This is called a temporally homogeneous discrete Markov chain because <fr:tex
display="inline"><![CDATA[p]]></fr:tex> does not depend on time.
  </fr:mainmatter><fr:backmatter><fr:tree
toc="false"
numbered="false"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:title
text="Context">Context</fr:title><fr:authors /></fr:frontmatter><fr:mainmatter><fr:tree
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="false"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>883</fr:anchor><fr:addr
type="user">kak-0040</fr:addr><fr:route>kak-0040.xml</fr:route><fr:title
text="Markov Chain">Markov Chain</fr:title><fr:taxon>Definition</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter><fr:p>	We say a stochastic process <fr:tex
display="inline"><![CDATA[X_n]]></fr:tex> is a Markov chain (MC) with transition matrix <fr:tex
display="inline"><![CDATA[p : \mathcal {S} \times  \mathcal {S} \to  [0, 1]]]></fr:tex> if for any <fr:tex
display="inline"><![CDATA[n \in  \mathcal {N}]]></fr:tex> and <fr:tex
display="inline"><![CDATA[x]]></fr:tex>, <fr:tex
display="inline"><![CDATA[y]]></fr:tex>, <fr:tex
display="inline"><![CDATA[x_{0}, \ldots  x_{n - 1}]]></fr:tex>
  <fr:tex
display="block"><![CDATA[ 		\mathbb {P}(X_{n + 1} = y \mid  X_{n} = x, X_{n - 1} = x_{n - 1}, \ldots , X_0 = x_0) = \mathbb {P}(X_{n + 1} = y \mid  X_n = x) = p(x, y)   ]]></fr:tex>
	whenever conditional probability is well-defined. 
	
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>571</fr:anchor><fr:addr
type="machine">#283</fr:addr><fr:route>unstable-283.xml</fr:route><fr:taxon>Remark</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter>
	Moreover, any matrix <fr:tex
display="inline"><![CDATA[p : \mathcal {S} \times  \mathcal {S} \to  [0, 1]]]></fr:tex> satisfying <fr:tex
display="inline"><![CDATA[\sum _{y \in  \mathcal {S}} p(x, y) = 1]]></fr:tex> is called a stochastic matrix. Given any stochastic matrix <fr:tex
display="inline"><![CDATA[p]]></fr:tex>, one can create a MC.
</fr:mainmatter><fr:backmatter /></fr:tree>

	
    <fr:tree
toc="false"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"><fr:frontmatter><fr:anchor>572</fr:anchor><fr:addr
type="machine">#284</fr:addr><fr:route>unstable-284.xml</fr:route><fr:taxon>Remark</fr:taxon><fr:date><fr:year>2025</fr:year><fr:month>1</fr:month><fr:day>30</fr:day></fr:date><fr:authors /></fr:frontmatter><fr:mainmatter>
		This is called a temporally homogeneous discrete Markov chain because <fr:tex
display="inline"><![CDATA[p]]></fr:tex> does not depend on time.
  </fr:mainmatter><fr:backmatter /></fr:tree></fr:p></fr:mainmatter><fr:backmatter /></fr:tree></fr:mainmatter><fr:backmatter /></fr:tree></fr:backmatter></fr:tree>